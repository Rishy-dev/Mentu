{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNhT+wLvpqB+wdcj1eZER2J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Hi! This shows you exactly how we have made the training model for Mentu, an AI lie detector. We have already trained a model for voice consistency in Google's Teachable Machine. We will then be connecting this to TenserFlow in python in order to render it. First get the required apps for this part of the project. You will find all of them in requirements/base.txt in my github. Next, simply download the teachable machine models using these code snippets."],"metadata":{"id":"LUq_B2e8paZT"}},{"cell_type":"code","source":["import requests\n","\n","model_url_base = \"https://teachablemachine.withgoogle.com/models/goMB9ACbx/\"\n","\n","# Download the model.json file\n","model_json_url = model_url_base + \"model.json\"\n","response_json = requests.get(model_json_url)\n","with open(\"model.json\", \"wb\") as f:\n","    f.write(response_json.content)\n","print(\"Downloaded model.json\")\n","\n","# Download the weights.bin file\n","weights_bin_url = model_url_base + \"weights.bin\"\n","response_weights = requests.get(weights_bin_url)\n","with open(\"weights.bin\", \"wb\") as f:\n","    f.write(response_weights.content)\n","print(\"Downloaded weights.bin\")\n","\n","# Download the metadata.json file (optional, but useful)\n","metadata_url = model_url_base + \"metadata.json\"\n","response_metadata = requests.get(metadata_url)\n","with open(\"metadata.json\", \"wb\") as f:\n","    f.write(response_metadata.content)\n","print(\"Downloaded metadata.json\")\n"],"metadata":{"id":"ZFkYvR5au6FP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","\n","model_url_base = \"https://teachablemachine.withgoogle.com/models/q8zdEmcC7/\"\n","\n","# Download the model.json file\n","model_json_url = model_url_base + \"model.json\"\n","response_json = requests.get(model_json_url)\n","with open(\"model.json\", \"wb\") as f:\n","    f.write(response_json.content)\n","print(\"Downloaded model.json\")\n","\n","# Download the weights.bin file\n","weights_bin_url = model_url_base + \"weights.bin\"\n","response_weights = requests.get(weights_bin_url)\n","with open(\"weights.bin\", \"wb\") as f:\n","    f.write(response_weights.content)\n","print(\"Downloaded weights.bin\")\n","\n","# Download the metadata.json file (optional, but useful)\n","metadata_url = model_url_base + \"metadata.json\"\n","response_metadata = requests.get(metadata_url)\n","with open(\"metadata.json\", \"wb\") as f:\n","    f.write(response_metadata.content)\n","print(\"Downloaded metadata.json\")\n"],"metadata":{"id":"tft1U6D0vHGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","\n","model_url_base = \"https://teachablemachine.withgoogle.com/models/1ujgBEAu3/\"\n","\n","# Download the model.json file\n","model_json_url = model_url_base + \"model.json\"\n","response_json = requests.get(model_json_url)\n","with open(\"model.json\", \"wb\") as f:\n","    f.write(response_json.content)\n","print(\"Downloaded model.json\")\n","\n","# Download the weights.bin file\n","weights_bin_url = model_url_base + \"weights.bin\"\n","response_weights = requests.get(weights_bin_url)\n","with open(\"weights.bin\", \"wb\") as f:\n","    f.write(response_weights.content)\n","print(\"Downloaded weights.bin\")\n","\n","# Download the metadata.json file (optional, but useful)\n","metadata_url = model_url_base + \"metadata.json\"\n","response_metadata = requests.get(metadata_url)\n","with open(\"metadata.json\", \"wb\") as f:\n","    f.write(response_metadata.content)\n","print(\"Downloaded metadata.json\")\n"],"metadata":{"id":"aoy3vMXavwxf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that you have downloaded the models, you  can simply use this code to run the machine learning model."],"metadata":{"id":"ddrwp1A9wFJg"}},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflowjs as tfjs\n","import numpy as np\n","from PIL import Image, ImageOps\n","import json\n","import os\n","\n","# Disable scientific notation for clarity\n","np.set_printoptions(suppress=True)\n","\n","# Define file paths\n","model_json_path = 'model.json'\n","metadata_path = 'metadata.json' # This file contains the labels\n","\n","# --- Load the model ---\n","# Use tensorflowjs library to load the model from the JSON file\n","try:\n","    model = tfjs.converters.load_keras_model(model_json_path)\n","    print(\"Model loaded successfully.\")\n","except Exception as e:\n","    print(f\"Error loading model: {e}\")\n","    # You might need to adjust paths if weights.bin is not in the same folder\n","\n","# --- Load the labels from metadata.json ---\n","with open(metadata_path, 'r') as f:\n","    metadata = json.load(f)\n","    # The labels are stored in the 'labels' key within metadata.json\n","    class_labels = metadata.get('labels', [])\n","\n","if not class_labels:\n","    print(\"Warning: Could not find labels in metadata.json.\")\n","\n","# The Teachable Machine model expects a specific input shape and normalization\n","IMAGE_SIZE = 224 # Most TM models are 224x224\n","data = np.ndarray(shape=(1, IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.float32)\n","\n","# Function to process an image for the model\n","def preprocess_image(image_path):\n","    image = Image.open(image_path).convert('RGB')\n","    # Resize the image to be at least 224x224 and then crop to 224x224\n","    size = (IMAGE_SIZE, IMAGE_SIZE)\n","    image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n","\n","    # Turn the image into a numpy array\n","    image_array = np.asarray(image)\n","\n","    # Normalize the image (TM uses specific normalization: (0-255) / 127.0 - 1)\n","    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1.0\n","\n","    # Load the image into the array\n","    data[0] = normalized_image_array\n","\n","# --- Example of how to use it: ---\n","test_image_path = 'testing/test_image.png' #Path on github\n","\n","if os.path.exists(test_image_path):\n","    preprocess_image(test_image_path)\n","\n","    # Run the inference\n","    prediction = model.predict(data)\n","\n","    # Get the index of the class with the highest confidence\n","    predicted_class_index = np.argmax(prediction)\n","\n","    if predicted_class_index < len(class_labels):\n","        predicted_class_label = class_labels[predicted_class_index]\n","        confidence_score = prediction[0][predicted_class_index]\n","\n","        print(\"-\" * 40)\n","        print(f\"Predicted class: {predicted_class_label}\")\n","        print(f\"Confidence score: {confidence_score:.2f}\")\n","        print(\"-\" * 40)\n","    else:\n","        print(\"Prediction successful, but index out of bounds for labels list.\")\n","\n","else:\n","    print(f\"\\nError: Test image not found at '{test_image_path}'. Please update the path.\")\n","\n"],"metadata":{"id":"Nu8kVx3jwnBf"},"execution_count":null,"outputs":[]}]}
